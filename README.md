# Visual Odometry for Localization in Autonomous Driving

This algorithm applies visual odometry to estimate the trajectory of a self-driving car. It processes images taken with a monocular camera set up on the vehicle.

This project is the programming assignment for *Module 2: Visual Features - Detection, Description and Matching* in the [Visual Perception for Self-Driving Cars](https://www.coursera.org/learn/visual-perception-self-driving-cars?) course. The started code is provided by the [University of Toronto](https://www.utoronto.ca/).

**The steps of this project are the following:**

- Extract features from the photographs taken with a camera setup on the vehicle.
- Use the extracted features to find matches between the features in different photographs.
- Use the found matches to estimate the camera motion between subsequent photographs.
- Use the estimated camera motion to build the vehicle trajectory.

## Preliminaries

In robotics and computer vision, **visual odometry** is defined as:

> The process of determining the position and orientation of a robot by analyzing the associated camera images.

Loading and Visualizing the Data

Feature Extraction

Feature Matching

Trajectory Estimation

References

